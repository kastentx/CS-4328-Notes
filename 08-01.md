### HW3 
* in part a) the total number shirts removed should not equal 1000

### Final Exam
* NOT cumulative

# Ch 10 Questions
* if valid/invalid bit is set to invalid, (AKA page not found in page table) - page fault occurs
  * this generates an interrupt - trap to OS
  * page is then loaded from the 'backing store' located on the disk
    * page is loaded into main memory in a free frame
    * the frame is updated in the page table and bit is set to 'valid'
* page-reference string with `m` frames and length `p`.
  * `n` distinct page numbers occur in it
  * the lowest number of page faults that can occur is `n` (every page gets loaded into memory once)
  * the highest number of page faults that can occur is `p` (page fault for every element in the string)
* 10.3
  * start with figuring out offset
  * 6 bits remain for frame #
  * page number is 20 bits
  * given address is in hex (each character makes 4 bits)
  * the first 20 bits of the virtual address correspond to the page number (AKA index in page table) 
    * value of this would be the frame number (first 6 bits of the physical address)
* 10.5
  * use the `EAT` algorithm
    * effective access time
  * looking for a solution with EAT < 200 nano sec
  * there are two outcomes - 'page fault' or 'no page fault'
  * start by adding in all the times listed in the prob:
    * 100 nanoseconds to access memory
    * 0 time to access page table (in registers)
  * if there IS a page fault, there are two different possibilities:
    * modified(70% of the time): 20 milliseconds
    * not modified (1 - .7 = 30% of the time): 8 milliseconds
  ```
  (x)(page fault) + (1-x)(page fault)
  (x)((.7)(modified) + (.3)(not modified)) + (1 - x)(0 + 100)
  (x)((.7)(0 + 20ms + 100ns) + (.3)(0 + 8ms + 100ns)) + (1 - x)(0 + 100ns)
  (x)((.7)(0 + 20ms + 100ns) + (.3)(0 + 8ms + 100ns)) + (1 - x)(0 + 100ns) < 200 nsec.

  solve for x
  ```
* 10.6 page replacement algo's
  * Optimal is the best
  * LRU is the second best
  * Second-Chance is the third best
  * FIFO is the worst
* 10.7
  * virtual memory has 2 schemes
    * paging:
      * loads things into memory (from disk) in 'page' size chunks
      * with the help of a page table, gives the effect of always having enough memory for what you need
      * the cost of this is the 6 step process needed to handle page faults
        * these costs will never outweigh the benefits
* 10.8 high paging disk utilization caused by thrashing
  * ways to help:
    * D - decrease the degree of multiprogramming (reduces the number of processes)
    * E - install more memory (this gives more frames)
    * F - faster hard disk (this will help, but not solve problem)
    * G - add prepaging to page fetch algorithm (this will help)
* 10.11
  * run through the string using 3 page frames for the individual algorithms
* 10.12
  * if not provided by hardware, implement 'reference bit' with software
  * can be introduced into the page table
    * put an additional field after the 'valid/invalid' bit
* 10.15
  * develop segment-replacing algorithms based on FIFO and LRU
  * divide the segments into 2 categories
    * relocatable & non-relocatable
    * very different ways of handling these two types
  * FIFO (not relocatable):
    * look at first-in segment
      * is it big enough? swap it out and you're done.
      * if not, look at the next oldest one
        * if that fits, swap that one.
* 10.18
* 10.19
  * the frame # would be equal to the base register
  * the limit register would be like the number of pages covered by this frame
* 10.20
  * cause of thrashing - too many processes loaded
  * detection - low CPU utilization, high disk utilization
  * to fix - swap out some processes
 

## Belady's anomaly
* string was `1 2 3 4 1 2 5 1 2 3 4 5`
* FIFO got 9 page faults out of 12 (using 3 frames)
  * got 10 page faults out of 12 (using 4 frames)
* **NOTE:** increasing frames does NOT always reduce page faults
* not all algorithms are succeptable to this..
  * FIFO & Second-Chance suffer from Belady's Anomaly

### LRU
* replaces the page that hasn't been used for the longest amount of time
* gets 10 page faults on the Belady string with 3 frames

### Optimal
* allows you to look into the future at what will be used / whats needed
* gets 7 page faults with 3 frames on the string above

### Second-Chance
* each page gets a reference bit (0 or 1) that indicates which ones have been most recently referenced
  * this is stored in a circular linked-list type structure
* if a page has a `1` in the reference bit it is useful, so we want to keep it (give it another chance)

