# HW 3
* critical sections must be well protected
* sample program given
  * our code won't be built from this
  * purpose is to show how to build threads/do mutual exclusion
* need to use C thread package
  * called `pthread`
  * pthread_create taskes several args
    * &tid (pointer), null, **function you want to run, null
* mutex locks will be used to protect critical sections
* we won't have to use wait/broadcast (like they do in the the example)
* critical section is located in between mutex lock/unlock
  * the first part of the assignment (that asks for problems) wouldn't use the mutex stuff
    * this is basically the only difference
* we will probably need 3 threads, each with their own function
  * could also be done with a shared function, with several parameters

# Know these for midterm friday!
* input / output
* pipe
* fork

# Module 9 - Memory Management

## Background
* **address binding** maps a logical address to a physical address
  * can happen at 3 different times:
    * compile time
    * load time
    * execution time
* **dynamic loading** means a program can be loaded into different places in memory when run on seperate occasions
* **overlays**
  * used when a program needs to be loaded that is larger than the main memory
    * load symbol table and common routines.. 
      * then only load the code needed to run current instructions (pass 1) then swap out (pass 2)
  * **relocation register** acts as the base number/adress to be added to the logical address (to produce physical address)
* OS is loaded first.. is the only program always running
* space in memory is dynamic, OS handles managing of this
  * 3 ways to allocate this:
    * **first-fit:** allocate the _first_ hole that is big enough
    * **best-fit:** allocate the _smallest_ hole that is big enough
      * must search entire list, unless list is ordered by size
      * produces the smallest leftover hole
    * **worst-fit** allocate the _largest_ hole
      * must also search entire list
      * produces the largest leftover hole
  * wasted space caused by this is called **internal fragmentation**
    * if wasted space _can_ be used by external processes, it's known as **external** fragmentation
* before CPU (logical address) is added to relocation register, first check the _limit register_
  * if less than, everything is OK
  * if not less than, trap to OS (illegal memory access)

## Memory Management Schemes
* the purpose of all these is to map a logical address (from the CPU) to a physical address

### Paging 
* divide MM into equal sized 'pages'
* since page sizes are all equal, no knowledge of given program is required
* in logical memory:
  * called a page
* in physical memory:
  * called a frame  
* size of page and frame must match exactly
* **page table** tells us the mapping of page number -> frame number
  * index is page number, value is frame number
* _formulas for calculating an address_
  * logical address of a byte: (page #) and (offset number)
  * physical address of a byte: (frame #) and (offset number)
  * if your memory space has 2^m bytes capacity, your address needs to be m bits long
    * think of simple example with 2^1 bytes (2 bytes) would need 2 addresses (0 and 1) AKA 1 bit
  * if whole address is `m` bits, in a space with `2^m` size
    * page size is `2^n` bits, so offset would need `n` bits
    * page number would need to be `m-n` bits
* memory is talked about in multiples of `2^k` becuase then you know how many bits needed for the address
* each process needs _its own_ page table
  * 3 processes -> 3 page tables
   
### Segmentation
* divide MM into different size 'segments'
* these pieces are sized based on the actual program in question

### Combination Scheme
* called a _segmented paging scheme_
  * one way to do this would be to divide each segment into equal size pages

### How to implement Page Table
* store it in fast memory
  * has to be large enough to hold the addresses, though
  * _main memory WITH cache_ is the best solution for this
    * main memory is large enough, but unfortunately kind of slow
    * cache is way faster, so it will make up for the shortcomings