# exam post-mortem
* what is a monitor?
  * has local variables
  * multiple functions
  * uses `signal()` and `wait()`
* how to modify mutual exclusion algorithm
  * change `s` to 3
* how to change state of process from 'running' to 'ready'
  * interrupt
* is starvation possible?
  * FIFO - starvation not possible
  * RR - starvation not possible
  * SJF - starvation possible
  * multilevel feedback queue - starvation possible
* scheduling / gantt chart
  * correct on test..
* barrier problem
  * solution not correct
  * count++ does not have proper protection.. can be updated by multiple processes at the same time
  * needs semaphore or something 
* dependency problem
  * instead of one semaphore with multiple incrementation.. needs 'S' for each process/criteria
* bankers algorithm
  * need to calculate the 'need' and 'available' columns
    * need = max - allocation
    * available = 1 1 2
      * need to look at whats left after ALL the allocations
    * p2,p0,p1,
* pipe/fork problem
  * child section correct
  * parent should: 
    * close 1
    * dup fd1
    * close fd0
    * close fd1
  * inputFd = open
  * close(0)
  * dup(inputFd)
  * close(inputFd)

76 is 91
(85 is 100)

# HW 3
* need to get started soon

# Memory Management
* much of this in 07-25 notes

### Inverted Page Table
* given a frame #, return a page #
* needs to store a pid with page, so we know to what process it belongs
* uses an inverted page table in the middle (to convert)
* IPT size is fixed (regardless of number of processes)
  * you only have one of these
    * this saves space, but loses efficiency

### Virtual Memory
* what if the page you need is not the one currently loaded
  * you can get a page fault
    * the **6 steps to handle this** are in the slides (page 7 - 10.7)
* main benefit: whole program doesn't need to be loaded in memory all at once 
* can offer 'demand-paging' or 'demand-segmentation'
  * only loads whats _needed_ into main memory
* needs the following hardware to be implemented:
  * backing store (disk)
  * main memory
* the effect for the user is similar to having unlimited amt of memory
  
### Page Replacement Algorithms  
* if there are no free frames, a 'page replacement algorithm' is used
  * FIFO (simplest one):
    * first attempt is a miss (empty cache)
    * then, the loaded ones get stored
    * first page in is the first one to get replaced if there's too many
    * lots of page faults.. not a great algorithm
  * Optimal:
    * first attempt is a miss (empty cache)
    * first three are faults, as they get loaded into cache
    * next, replace the page that will not be used for the longest period of time
    * requires you to know the future, though...
  * look at the past (least recently used):
    * replace the page that hasn't been used for the longest period of time in the past
      * AKA swap out the one that's been sitting unused the longest
  * least recently used #2 (variation)
    * additional reference bits
    * each page maintains a string of 'reference bits'
      * when it gets used, make the fist bit a 1
      * after T units of time, shift all bits to the right by one
      * swap out the page with the furthest-to-the-right `1` bit
    * you want to use a proper amount of bits in the string.. not too few, not too many
  * 2nd chance algorithm:
    * link pages with a circular linked list
      * pointer (for next)
      * reference bit
    * when going to swap out..
      * if reference bit == 0, page can be swapped out
      * if reference bit == 1, set it to 0 and move pointer to the next
  * Counting algorithm:
    * a counter (for each page) keeps track of how many times the page has been accessed
      * swap out the one with the lowest number to get rid of least frequently used
      * swap out the one with the highest number to get rid of most frequently used
    * either method can be used (with slightly different results)
  * _enhanced_ 2nd chance algorithm
    * each page has a reference bit and a modify bit
      * this tracks if a page has been accessed and/or modified

### Frame allocation strategies
1. 'Fair' allocation strategy
  * split it up evenly among the processes
  * however, not all processes are the same size
2. Proportional allocation
  * base the number of frames allocated on the size relative to total # available

### Cache Thrashing
* degree of multiprogramming == number of processes that can be loaded into the system
  * as the number increases, CPU utilization will go up
    * after a certain point though, CPU utilization will go down (won't ever get to 100%)
      * this is called the saturation point.. is where cache 'thrashing' occurs
        * cache thrashing will significantly slow down the system
        * more time that the CPU is sitting there 'idle'

### Counting Algorithms

### Page Sizes
* 4096 byes, 4K, 8K, 64K, 512K, 4MB
  * these are all `2^n` because then it maps directly to an address of `n` bits
* the size is based on several factors:
  1. fragmentation
    * leftover memory in a partition that has been allocated to a process
    * there is both _internal_ and _external_ fragmentation
      * internal (paging scheme) can only be used by that process, external (segmentation scheme) by any process
        * because in paging scheme, we only allocate by page
  2. table size
  3. IO overhead
  4. locality