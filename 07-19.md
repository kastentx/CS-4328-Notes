## Producer/Consumer w/ Java

### Shared Memory example
* given code has no synchronization mechanisms (protection)
  * not a correct example
  * producer can call b.enter() and b.remove() and have both access memory(buffer) at the same time
    * violates one of the criteria
* 2 functions, `enter` and `remove`

### Semaphore example
* correct example
* wraps code in `enter` and `remove` with proper mutex and empty/full calls
  * ensures that only one thread can access the shared mem at a time
  * uses Java keyword `synchronized`
* 

### pc-syn
* correct example
* producer and consumer class are the same, but also has `Buffer` class
* uses `synchronized` before `enter`
  * takes advantage of Java 'lock' mechanism

# Module 5

## Threads
* process vs. thread
  * in a process, multiple threads can be created (if machine supports it)
  * a thread is a _lightweight process_
  * similar to PCBs for processes, threads have some data
    * TID (thread id)
    * PC
    * Registers
    * stack
  * among them, threads can share things like code section, data, open files & signals..
    * because of this, 'context-switching' can be must faster between threads
    * reduced amount of saving/loading, which is a slow operation
  * less expensive to create a thread than a process

### User Threads vs Kernel Threads
* Kernel threads are directly created by the kernel
  * not in the user space
  * OS can tell if they get blocked, schedule another thread
    * implements 'true parallelism' (not possible with user threads)
* other than the differences, threads are the exact same as processes

### Lifecycle of a Process
* majority of processes have a very short 'CPU burst time'

### CPU Scheduler
* CPU scheduling decisions happen when processes switch states or terminate
* a good scheduling algorithm keeps the CPU as busy as possible
  * other metrics include: throughput, turnaround time, waiting time, response time
* 'turnaround time' is the time from beginning to end of execution for a process
* 'waiting time' for a process is the sum of all the periods of waiting
* 'response time' is the time from beginning to the _first response_, not output

### scheduling algos
* **FCFS** - first come, first served
  * gantt chart will show the schedule for processes
    * uses an estimated burst time to show when each process should finish
    * can be vertical or horizontal
    * avg waiting time can be calculated by dividing (total time) by (num of processes)
      * better schedule can reduce the avg waiting time
  * fair, but not efficient
* **SJF** - shortest job first (optimal due to smallest avg waiting time)
  * run whatever the shortest job is first
  * can be preemptive or non-preemptive
    * 'non-preemptive' means a newer, shorter job _cannot_ interrupt
    * 'preemptive' means CPU can be taken away by a new job
      * time of new job gets compared to _remaining time_ of current process

### Burst Time
* estimated burst time is calculated with a formula
  * weighted combination of 'most-recent' history with past history

### Priority Scheduling
* proceses are scheduled according to their priority
* also uses preemptive and non-preemptive methods

### Round Robin
* each process gets a small amount of CPU time that rotates around
  * called a **time quantum**
* has a higher avg turnaround time than SJF, but a better _response time_
* small time quantum leads to a lot of context switching, overhead
* large time quantum creates a similar situation to first come, first serve
* turnaround time has _no relation_ to the time quantum

### Multilevel Queue
* Ready queue is partitioned into seperate queues:
  * foreground (interactive)
  * background (batch)
* as queues get deeper into the layers, time quantum gets longer
  * bottom level is FCFS

### Guaranteed scheduling
* uses a ratio:
  * (actual CPU time given) / (CPU time entitled) 

### Lottery Scheduling
* 100 tickets
* client and server processes
* distribution of tickets determines percent chance to get CPU time

## Module 8: Deadlocks
